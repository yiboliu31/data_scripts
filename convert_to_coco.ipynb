{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity Set to Coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/dean/anaconda3/envs/ros-kache/lib/python35.zip', '/home/dean/anaconda3/envs/ros-kache/lib/python3.5', '/home/dean/anaconda3/envs/ros-kache/lib/python3.5/plat-linux', '/home/dean/anaconda3/envs/ros-kache/lib/python3.5/lib-dynload', '/home/dean/.local/lib/python3.5/site-packages', '/home/dean/anaconda3/envs/ros-kache/lib/python3.5/site-packages', '/home/dean/anaconda3/envs/ros-kache/lib/python3.5/site-packages/IPython/extensions', '/home/dean/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/anaconda3/envs/ros-kache/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import scipy.misc\n",
    "from skimage import measure   \n",
    "\n",
    "import time\n",
    "import os\n",
    "import zipfile as zf\n",
    "import tarfile\n",
    "import csv\n",
    "import pickle\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset Parameters ##\n",
    "TRAINING_DATASET_DIRECTORY = 'training-set/'\n",
    "WORKING_DIRECTORY = '/media/dean/49D9D6EB1BE53FC4/datasets/UdacityDrive/object-detection-crowdai/'\n",
    "OBJ_NEGATIVES_TOKEN = 'non_objects'\n",
    "dataset_path = \"{}{}{}{}\".format(WORKING_DIRECTORY, TRAINING_DATASET_DIRECTORY,'**/', '*.png')\n",
    "DATACACHE_DIRECTORY = os.path.join(WORKING_DIRECTORY, 'datacache/')\n",
    "\n",
    "\n",
    "## Udacity Dataset Extraction Parameters ##\n",
    "UDACITY_ANNS_CSV = os.path.join(WORKING_DIRECTORY, 'labels.csv')\n",
    "HEADER_ROW=['xstart', 'ystart', 'xstop', 'ystop', 'frame', 'label', 'preview_url']\n",
    "UDACITY_SOURCE_URL = 'http://bit.ly/udacity-annoations-crowdai'\n",
    "DATASET_ZIPFILE = 'object-detection-crowdai.tar.gz'\n",
    "OVERWRITE_UDACITY_DATASET = False\n",
    "UDACITY_DATASET_DIRECTORY = os.path.join(WORKING_DIRECTORY, TRAINING_DATASET_DIRECTORY, 'udacity-set') \n",
    "\n",
    "## RoadCOCO Dataset Labels\n",
    "RoadCOCO_LABELS_PATH = os.path.join(WORKING_DIRECTORY, '../','RoadCOCO_Classes.csv')\n",
    "GT_HEADER_ROW = ['class', 'super-category', 'special', 'description']\n",
    "\n",
    "## Image Processing ##\n",
    "DEFAULT_WIDTH, DEFAULT_LENGTH, DEFAULT_DEPTH = (448, 448, 3)\n",
    "DEFAULT_RESOLUTION = (DEFAULT_LENGTH, DEFAULT_WIDTH, DEFAULT_DEPTH)\n",
    "if DEFAULT_DEPTH == 1:\n",
    "    DEFAULT_RESOLUTION = DEFAULT_RESOLUTION[:-1]\n",
    "    \n",
    "## Training Parameters ##\n",
    "OVERWRITE_DATACACHE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions - Udacity Dataset Loading & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to scale .PNG and JPEG Files both to 0 to 1 \n",
    "def normalize_pixels(img):\n",
    "    max_pixel_value = np.max(img)\n",
    "    if max_pixel_value > 1.0:\n",
    "        img = np.copy(np.subtract(np.divide(img, 255.0), 0.5)).astype(np.float64)\n",
    "    return img\n",
    "\n",
    "# Define a function to scale .PNG and JPEG Files both to 0 to 1 \n",
    "def denormalize_pixels(img):    \n",
    "    img = np.copy(np.multiply(np.add(img,0.5), 255.0)).astype(np.int32)  \n",
    "    assert np.min(img) >= 0\n",
    "    assert np.max(img) <= 255\n",
    "    return img\n",
    "\n",
    "def process_img(filepath):\n",
    "    image = cv2.imread(filepath)\n",
    "    img_copy = image.copy()\n",
    "    img_copy = cv2.cvtColor(img_copy,cv2.COLOR_BGR2RGB)\n",
    "    img_copy = img_copy/255.-.5 \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(source_url, filename):\n",
    "    if not os.path.exists(WORKING_DIRECTORY):\n",
    "        os.mkdir(WORKING_DIRECTORY)\n",
    "    \n",
    "    filepath = os.path.join(WORKING_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(source_url, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('')\n",
    "        print('Succesfully downloaded:', filepath, '| % d MB.' % int(statinfo.st_size*1e-6))\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(zip_file, source_dir_name=None, destination=WORKING_DIRECTORY):\n",
    "    if 'tar.gz' in zip_file:\n",
    "        head, tail = os.path.splitext(zip_file)\n",
    "        if not os.path.exists(os.path.join(os.path.splitext(head)[0])):\n",
    "            print('unzipping file:', zip_file, 'to directory:', os.path.join( os.path.splitext(head)[0]))\n",
    "            tar = tarfile.open(zip_file, \"r:*\")\n",
    "            tar.extractall(destination)\n",
    "            tar.close()\n",
    "    else: #.zip extension\n",
    "        head, tail = os.path.splitext(zip_file)\n",
    "        if not os.path.exists(os.path.join(destination, head)):\n",
    "            print('File does not exist: ', os.path.join(destination, head), ': Extracting')\n",
    "            zipf = zf.ZipFile(os.path.join(WORKING_DIRECTORY,zip_file))\n",
    "            print('Loaded zipf',zipf, ': Extracting')\n",
    "            zipf.extractall(os.path.join(destination, head))\n",
    "            zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_preprocess_image(filepath, objs_dir, nonobjs_dir, xstart, ystart, xstop, ystop, obj_class,\n",
    "                                 img_size=(DEFAULT_LENGTH, DEFAULT_WIDTH), img_ext = '.png'):\n",
    "    full_path = os.path.join(WORKING_DIRECTORY, 'object-detection-crowdai', filepath)    \n",
    "    # Image read in from cv2 + .jpg -> (0 to 1)\n",
    "    if os.path.exists(full_path) or OVERWRITE_UDACITY_DATASET == True:\n",
    "        # Use cv2 to open image and extract bounding boxes\n",
    "        img = process_img(full_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        # Extract Image. Note: numpy arrays are (row, col)!\n",
    "        \n",
    "        # Add Offests to allow for Object Detection Tasks\n",
    "        offset = 20\n",
    "        xstart_mod, ystart_mod, xstop_mod, ystop_mod =  (0 if xstart-offset <= 0 else xstart-offset), \\\n",
    "                                                        (0 if ystart-offset <= 0 else ystart-offset), \\\n",
    "                                                        (img_width if xstop+offset > img_width else xstop+offset), \\\n",
    "                                                        (img_height if ystop+offset > img_height else ystop+offset)\n",
    "            \n",
    "        detection = img[ystart_mod:ystop_mod, xstart_mod:xstop_mod]\n",
    "        resized_detection = cv2.resize(detection, img_size, interpolation=cv2.INTER_AREA)\n",
    "        denorm = denormalize_pixels(resized_detection)        \n",
    "\n",
    "                \n",
    "        # Save Detected Object Image with offsets\n",
    "        filename, ext = os.path.splitext(filepath)\n",
    "        new_filename =  \"{}_{}_{}_{}_{}_{}{}\".format(filename,obj_class, xstart, ystart, xstop, ystop, img_ext)\n",
    "        scipy.misc.imsave(os.path.join(objs_dir, new_filename), denorm)\n",
    "        \n",
    "\n",
    "        ## (Optional) Auto-Generate 'Negative Class' Labels to keep dataset balanced\n",
    "        i_lrc = np.random.randint(3) # 66% chance of auto generating non-obj features\n",
    "        if (i_lrc > 1):\n",
    "            try:\n",
    "                # Estimate Negative Label as crop surrounding the Positive Detections\n",
    "                xstart_mod, ystart_mod, xstop_mod, ystop_mod = xstart, \\\n",
    "                                                        (0 if ystart-(ystop-ystart) < 0 else ystart-(ystop-ystart)), xstop, ystart\n",
    "                new_filename =  \"{}_{}_{}_{}_{}_{}{}\".format(filename,'non_'+obj_class.lower(), xstart_mod, ystart_mod, xstop_mod, ystop_mod, img_ext)\n",
    "                path_file = os.path.join(nonobjs_dir, new_filename)\n",
    "\n",
    "\n",
    "                nonobj_img = img[ystart_mod:ystop_mod, xstart_mod:xstop_mod]\n",
    "                resized_nonobj_img = cv2.resize(nonobj_img, img_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Save Negative Label\n",
    "                scipy.misc.imsave(path_file, resized_nonobj_img)\n",
    "            except:\n",
    "                print(\"Error saving negative label:\", path_file, \" Moving on..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Udacity Dataset\n",
    "tar_file = maybe_download( UDACITY_SOURCE_URL, os.path.join(WORKING_DIRECTORY,DATASET_ZIPFILE))\n",
    "unzip_file(tar_file)\n",
    "                    \n",
    "cars_dir = os.path.join(UDACITY_DATASET_DIRECTORY, 'cars')\n",
    "trucks_dir = os.path.join(UDACITY_DATASET_DIRECTORY, 'trucks')\n",
    "peds_dir = os.path.join(UDACITY_DATASET_DIRECTORY, 'pedestrians')\n",
    "\n",
    "# Make Directory for Negative Annotations\n",
    "nonobjs_dir = os.path.join(UDACITY_DATASET_DIRECTORY, OBJ_NEGATIVES_TOKEN)\n",
    "noncars_dir = os.path.join(nonobjs_dir, 'non_cars')\n",
    "nontrucks_dir = os.path.join(nonobjs_dir, 'non_trucks')\n",
    "nonpeds_dir = os.path.join(nonobjs_dir, 'non_peds')\n",
    "\n",
    "# Create Directories to store images for Pre-processing\n",
    "os.makedirs(cars_dir, exist_ok=True)\n",
    "os.makedirs(trucks_dir, exist_ok=True)\n",
    "os.makedirs(peds_dir, exist_ok=True)\n",
    "os.makedirs(noncars_dir, exist_ok=True)\n",
    "os.makedirs(nontrucks_dir, exist_ok=True)\n",
    "os.makedirs(nonpeds_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xstart</th>\n",
       "      <th>ystart</th>\n",
       "      <th>xstop</th>\n",
       "      <th>ystop</th>\n",
       "      <th>frame</th>\n",
       "      <th>label</th>\n",
       "      <th>preview_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>785</td>\n",
       "      <td>533</td>\n",
       "      <td>905</td>\n",
       "      <td>644</td>\n",
       "      <td>1479498371963069978.jpg</td>\n",
       "      <td>Car</td>\n",
       "      <td>http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>551</td>\n",
       "      <td>291</td>\n",
       "      <td>680</td>\n",
       "      <td>1479498371963069978.jpg</td>\n",
       "      <td>Car</td>\n",
       "      <td>http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268</td>\n",
       "      <td>546</td>\n",
       "      <td>383</td>\n",
       "      <td>650</td>\n",
       "      <td>1479498371963069978.jpg</td>\n",
       "      <td>Car</td>\n",
       "      <td>http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>455</td>\n",
       "      <td>522</td>\n",
       "      <td>548</td>\n",
       "      <td>615</td>\n",
       "      <td>1479498371963069978.jpg</td>\n",
       "      <td>Truck</td>\n",
       "      <td>http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>548</td>\n",
       "      <td>522</td>\n",
       "      <td>625</td>\n",
       "      <td>605</td>\n",
       "      <td>1479498371963069978.jpg</td>\n",
       "      <td>Truck</td>\n",
       "      <td>http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xstart  ystart  xstop  ystop                    frame  label  \\\n",
       "0     785     533    905    644  1479498371963069978.jpg    Car   \n",
       "1      89     551    291    680  1479498371963069978.jpg    Car   \n",
       "2     268     546    383    650  1479498371963069978.jpg    Car   \n",
       "3     455     522    548    615  1479498371963069978.jpg  Truck   \n",
       "4     548     522    625    605  1479498371963069978.jpg  Truck   \n",
       "\n",
       "                                         preview_url  \n",
       "0  http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...  \n",
       "1  http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...  \n",
       "2  http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...  \n",
       "3  http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...  \n",
       "4  http://crowdai.com/images/Wwj-gorOCisE7uxA/vis...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Extract Labels ##\n",
    "annotations = pd.read_csv(UDACITY_ANNS_CSV, names=HEADER_ROW, skiprows=1)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract Labels ## - Skip for Now      \n",
    "# for label in annotations.as_matrix():\n",
    "#     filename, ext = os.path.splitext(label[4])\n",
    "#     new_filename =  \"{}_{}_{}_{}_{}_{}{}\".format(filename,label[5].lower(), label[0], label[1], label[2], label[3], '.png')\n",
    "    \n",
    "#     for obj_class in set(annotations['label'].tolist()):\n",
    "#         if not os.path.exists(os.path.join(cars_dir, new_filename)) and label[5].lower() == obj_class.lower():\n",
    "#             extract_and_preprocess_image(label[4], cars_dir, noncars_dir, xstart=label[0], ystart=label[1],\n",
    "#                                          xstop=label[2], ystop=label[3], obj_class=obj_class)\n",
    "#         elif not os.path.exists(os.path.join(trucks_dir, new_filename)) and label[5].lower() == obj_class.lower():\n",
    "#             extract_and_preprocess_image(label[4], trucks_dir, nontrucks_dir, xstart=label[0], ystart=label[1],\n",
    "#                                          xstop=label[2], ystop=label[3], obj_class=obj_class)\n",
    "#         elif not os.path.exists(os.path.join(peds_dir, new_filename)) and label[5].lower() == obj_class.lower():\n",
    "#             extract_and_preprocess_image(label[4], peds_dir, nonpeds_dir, xstart=label[0], ystart=label[1],\n",
    "#                                          xstop=label[2], ystop=label[3], obj_class=obj_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>super-category</th>\n",
       "      <th>special</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>Vehicle</td>\n",
       "      <td>Orientation matters</td>\n",
       "      <td>Combination of all other vehicles to get a cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Car</td>\n",
       "      <td>Vehicle</td>\n",
       "      <td>Orientation matters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pickup</td>\n",
       "      <td>Truck</td>\n",
       "      <td>Orientation matters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TractorSemi</td>\n",
       "      <td>Truck</td>\n",
       "      <td>Orientation matters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrailerSemi</td>\n",
       "      <td>Truck</td>\n",
       "      <td>Orientation matters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         class super-category              special  \\\n",
       "0      Vehicle        Vehicle  Orientation matters   \n",
       "1          Car        Vehicle  Orientation matters   \n",
       "2       Pickup          Truck  Orientation matters   \n",
       "3  TractorSemi          Truck  Orientation matters   \n",
       "4  TrailerSemi          Truck  Orientation matters   \n",
       "\n",
       "                                         description  \n",
       "0  Combination of all other vehicles to get a cat...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get RoadCOCO Labels to Use as Ground Truth\n",
    "gt_labels = pd.read_csv(RoadCOCO_LABELS_PATH, names=GT_HEADER_ROW, skiprows=1)\n",
    "gt_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 62, 'name': 'vehicle', 'supercategory': 'vehicle'}, {'id': 8, 'name': 'car', 'supercategory': 'vehicle'}, {'id': 37, 'name': 'pickup', 'supercategory': 'utilitytruck'}, {'id': 52, 'name': 'tractorsemi', 'supercategory': 'utilitytruck'}, {'id': 60, 'name': 'trailersemi', 'supercategory': 'utilitytruck'}, {'id': 21, 'name': 'firetruck', 'supercategory': 'utilitytruck'}, {'id': 0, 'name': 'ambulance', 'supercategory': 'utilitytruck'}, {'id': 39, 'name': 'police', 'supercategory': 'vehicle'}, {'id': 10, 'name': 'constructionequipment', 'supercategory': 'constructionequipment'}, {'id': 34, 'name': 'motorcycle', 'supercategory': 'vehicle'}, {'id': 43, 'name': 'scooter', 'supercategory': 'person'}, {'id': 4, 'name': 'bicyclist', 'supercategory': 'vehicle'}, {'id': 20, 'name': 'escooter', 'supercategory': 'vehicle'}, {'id': 45, 'name': 'skateboard', 'supercategory': 'misc_label'}, {'id': 64, 'name': 'wheelchair', 'supercategory': 'person'}, {'id': 51, 'name': 'stroller', 'supercategory': 'person'}, {'id': 48, 'name': 'snowplow', 'supercategory': 'vehicle'}, {'id': 2, 'name': 'attenuatortruck', 'supercategory': 'utilitytruck'}, {'id': 26, 'name': 'garbagetruck', 'supercategory': 'utilitytruck'}, {'id': 17, 'name': 'deliverytruck', 'supercategory': 'utilitytruck'}, {'id': 6, 'name': 'boxtruck', 'supercategory': 'utilitytruck'}, {'id': 7, 'name': 'bus', 'supercategory': 'utilitytruck'}, {'id': 1, 'name': 'articulatedbus', 'supercategory': 'utilitytruck'}, {'id': 42, 'name': 'schoolbus', 'supercategory': 'utilitytruck'}, {'id': 30, 'name': 'metermaid', 'supercategory': 'person'}, {'id': 61, 'name': 'utilitytruck', 'supercategory': 'utilitytruck'}, {'id': 44, 'name': 'shoppingcart', 'supercategory': 'person'}, {'id': 36, 'name': 'person', 'supercategory': 'person'}, {'id': 12, 'name': 'constructionworker', 'supercategory': 'person'}, {'id': 58, 'name': 'trafficofficer', 'supercategory': 'person'}, {'id': 25, 'name': 'garbagecan', 'supercategory': 'misc_label'}, {'id': 24, 'name': 'garbagebin', 'supercategory': 'misc_label'}, {'id': 47, 'name': 'snowfence', 'supercategory': 'misc_label'}, {'id': 33, 'name': 'mobilefence', 'supercategory': 'misc_label'}, {'id': 23, 'name': 'foldingbarricade', 'supercategory': 'misc_label'}, {'id': 19, 'name': 'dumpster', 'supercategory': 'misc_label'}, {'id': 32, 'name': 'mobilebathroom', 'supercategory': 'misc_label'}, {'id': 50, 'name': 'stopsign', 'supercategory': 'trafficsign'}, {'id': 46, 'name': 'slowsign', 'supercategory': 'trafficsign'}, {'id': 49, 'name': 'speedlimitsign', 'supercategory': 'trafficsign'}, {'id': 59, 'name': 'trafficsign', 'supercategory': 'trafficsign'}, {'id': 22, 'name': 'flare', 'supercategory': 'misc_label'}, {'id': 5, 'name': 'botsdots', 'supercategory': 'misc_label'}, {'id': 41, 'name': 'retroreflector', 'supercategory': 'misc_label'}, {'id': 40, 'name': 'pothole', 'supercategory': 'misc_label'}, {'id': 18, 'name': 'dog', 'supercategory': 'misc_label'}, {'id': 16, 'name': 'deer', 'supercategory': 'misc_label'}, {'id': 13, 'name': 'cow', 'supercategory': 'misc_label'}, {'id': 27, 'name': 'horse', 'supercategory': 'misc_label'}, {'id': 28, 'name': 'livestock', 'supercategory': 'misc_label'}, {'id': 35, 'name': 'otheranimal', 'supercategory': 'misc_label'}, {'id': 63, 'name': 'wheel', 'supercategory': 'misc_label'}, {'id': 14, 'name': 'debrisdrivable', 'supercategory': 'misc_label'}, {'id': 15, 'name': 'debrisnondrivable', 'supercategory': 'misc_label'}, {'id': 3, 'name': 'barrel', 'supercategory': 'constructionequipment'}, {'id': 38, 'name': 'pole', 'supercategory': 'constructionequipment'}, {'id': 9, 'name': 'cone', 'supercategory': 'constructionequipment'}, {'id': 11, 'name': 'constructionsign', 'supercategory': 'constructionequipment'}, {'id': 29, 'name': 'median', 'supercategory': 'constructionequipment'}, {'id': 54, 'name': 'trafficlightgeneral', 'supercategory': 'trafficsign'}, {'id': 55, 'name': 'trafficlightgreen', 'supercategory': 'trafficsign'}, {'id': 57, 'name': 'trafficlightred', 'supercategory': 'trafficsign'}, {'id': 53, 'name': 'trafficlightamber', 'supercategory': 'trafficsign'}, {'id': 56, 'name': 'trafficlightother', 'supercategory': 'trafficsign'}, {'id': 31, 'name': 'misc_label', 'supercategory': 'misc_label'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/anaconda3/envs/ros-kache/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Represent Category IDs using RoadCOCO Labels\n",
    "cats2ids = {}\n",
    "for i, label in enumerate(sorted(set(gt_labels['class'].tolist()))):\n",
    "    cats2ids[str(label).lower()] = i\n",
    "ids2cats = {i: v for v, i in cats2ids.items()}\n",
    "    \n",
    "\n",
    "\n",
    "# Build Categories List in MS RoadCOCO Format\n",
    "coco_categories = [] \n",
    "for label in gt_labels.as_matrix():\n",
    "    category = str(label[0]).lower()\n",
    "    cat_id = cats2ids[category]\n",
    "    \n",
    "    \n",
    "    # Verify super-category in list, handle edge cases\n",
    "    if str(label[1]).lower() == 'truck':\n",
    "        sup_cat = ids2cats[cats2ids['utilitytruck']]\n",
    "    elif str(label[1]).lower() == 'constructionfurniture':\n",
    "        sup_cat = ids2cats[cats2ids['constructionequipment']]\n",
    "    elif str(label[1]).lower() == 'pedestrian':\n",
    "        sup_cat = ids2cats[cats2ids['person']]\n",
    "    else:\n",
    "        sup_cat = ids2cats[cats2ids[str(label[1]).lower()]]\n",
    "    \n",
    "    coco_categories.append({\"id\": cat_id, \"name\": category, \"supercategory\":sup_cat})   \n",
    "print (coco_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/anaconda3/envs/ros-kache/lib/python3.5/site-packages/ipykernel/__main__.py:30: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Script to convert Udacity Drive Annotations to Coco Json Annotations\n",
    "import xml.etree.cElementTree as ET\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "from PIL import Image\n",
    "annotations = pd.read_csv(UDACITY_ANNS_CSV, names=HEADER_ROW, skiprows=1)\n",
    "\n",
    "\n",
    "images, anns = [], []\n",
    "img_paths = set(annotations['frame'].tolist())\n",
    "\n",
    "num_imgs = len(img_paths)\n",
    "ann_index = 0\n",
    "    \n",
    "for img_id, f in enumerate(sorted(img_paths)):\n",
    "    im = Image.open(os.path.join(WORKING_DIRECTORY, f))\n",
    "    width, height = im.size\n",
    "    dic = {'file_name': f, 'id': img_id, 'height': height, 'width': width}\n",
    "    images.append(dic)\n",
    "    binary_mask = np.zeros_like(im)[:,:,0]\n",
    "    \n",
    "    for annotation in [x for x in annotations.as_matrix() if x[4].lower() == f.lower()]:\n",
    "        # xy coords: [xstart, ystart, xstop, ystop] -> bbox = [x,y,width,height]\n",
    "        xstart, ystart, xstop, ystop = annotation[0], annotation[1], \\\n",
    "                                       annotation[2], annotation[3]        \n",
    "        binary_mask[xstart:xstop, ystart:ystop] +=1\n",
    "        \n",
    "        \n",
    "    contours = measure.find_contours(binary_mask, 0.5, positive_orientation='low')\n",
    "    polygons = []\n",
    "    segmentations = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Flip from (row, col) representation to (x, y)\n",
    "        # and subtract the padding pixel\n",
    "        # for i in range(len(contour)):\n",
    "        #     row, col = contour[i]\n",
    "        #     contour[i] = (col - 1, row - 1)\n",
    "\n",
    "        # Make a polygon and simplify it\n",
    "        poly = Polygon(contour)\n",
    "        poly = poly.simplify(1.0, preserve_topology=False)\n",
    "\n",
    "        if poly and poly.exterior:\n",
    "            polygons.append(poly)\n",
    "            segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "    # Combine the polygons to calculate the bounding box and area\n",
    "    multi_poly = MultiPolygon(polygons)\n",
    "    if multi_poly.bounds:\n",
    "        x, y, max_x, max_y = multi_poly.bounds\n",
    "        width = max_x - x\n",
    "        height = max_y - y\n",
    "        bbox = (x, y, width, height)\n",
    "        area = multi_poly.area\n",
    "\n",
    "        # Get Label\n",
    "        if annotation[5].lower() in cats2ids.keys():\n",
    "            category = cats2ids[annotation[5].lower()]\n",
    "        else:\n",
    "            # Flag data point for relabeling\n",
    "            category = cats2ids['misc_label']\n",
    "\n",
    "        annotation = {\n",
    "            'segmentation': segmentations,\n",
    "            'iscrowd': 0,\n",
    "            'image_id': img_id,\n",
    "            'category_id': category,\n",
    "            'id': ann_index,\n",
    "            'bbox': bbox,\n",
    "            'area': area\n",
    "        }\n",
    "        ann_index+=1\n",
    "        anns.append(annotation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anns[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "INFO = {\n",
    "    \"description\": \"Road Object-Detections Dataset based on MS COCO\",\n",
    "    \"url\": \"https://kache.ai\",\n",
    "    \"version\": \"0.0.1\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"deanwebb\",\n",
    "    \"date_created\": datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"The MIT License (MIT)\",\n",
    "        \"url\": \"https://opensource.org/licenses/MIT\",\n",
    "        \"description\":  \"\"\"\n",
    "                        The MIT License (MIT)\n",
    "                        Copyright (c) 2017 Matterport, Inc.\n",
    "\n",
    "                        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "                        of this software and associated documentation files (the \"Software\"), to deal\n",
    "                        in the Software without restriction, including without limitation the rights\n",
    "                        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "                        copies of the Software, and to permit persons to whom the Software is\n",
    "                        furnished to do so, subject to the following conditions:\n",
    "\n",
    "                        The above copyright notice and this permission notice shall be included in\n",
    "                        all copies or substantial portions of the Software.\n",
    "\n",
    "                        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "                        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "                        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "                        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "                        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "                        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "                        THE SOFTWARE.\n",
    "                        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "coco_output = {'info': INFO, 'licenses': LICENSES, 'images':images, 'annotations':anns, 'categories': coco_categories}\n",
    "with open('{}/instances_shape_train2018.json'.format(WORKING_DIRECTORY), 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = WORKING_DIRECTORY\n",
    "annotation_file = os.path.join(WORKING_DIRECTORY,'instances_shape_train2018.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = example_coco.loadCats(example_coco.getCatIds())\n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom COCO categories: \\n{}\\n'.format(' '.join(category_names)))\n",
    "\n",
    "category_names = set([category['supercategory'] for category in categories])\n",
    "print('Custom COCO supercategories: \\n{}'.format(' '.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = example_coco.getCatIds(catNms=['square'])\n",
    "image_ids = example_coco.getImgIds(catIds=category_ids)\n",
    "image_data = example_coco.loadImgs(image_ids[np.random.randint(0, len(image_ids))])[0]\n",
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "image = io.imread(os.path.join(image_directory ,image_data['file_name']))\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (68.0, 120.0)\n",
    "annotation_ids = example_coco.getAnnIds(imgIds=image_data['id'], catIds=category_ids, iscrowd=None)\n",
    "annotations = example_coco.loadAnns(annotation_ids)\n",
    "example_coco.showAnns(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ros-kache]",
   "language": "python",
   "name": "conda-env-ros-kache-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
