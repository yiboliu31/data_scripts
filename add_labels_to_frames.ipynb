{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pipelineapi import PipelineAPI\n",
    "\n",
    "def get_dataset(anns_dir, data_pipeline_api, dataset_names):\n",
    "    task, file_name = data_pipeline_api.data_file(video_source_names=[], dataset_names=dataset_names,\n",
    "                categories_names=[], label_statuses=[], bulk_size=6000)\n",
    "    print(task) ; print(file_name)\n",
    "\n",
    "    while not os.path.exists(os.path.join(anns_dir, os.path.splitext(file_name)[0]+'_1.json')):\n",
    "        \n",
    "        print(data_pipeline_api.get_file(task_id=task, folder=anns_dir))\n",
    "        time.sleep(30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2acc1ffb-f6a3-420e-9f43-6026003246ce\n",
      "20a4e97c-256d-42b8-937f-ec18600165a6.zip\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "IN PROCESS\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "IN PROCESS\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "None\n",
      "/media/dean/datastore/datapipeline_api_dir/all_frames/\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "anns_dir = '/media/dean/datastore/datapipeline_api_dir/all_frames/'\n",
    "data_pipeline_api =  PipelineAPI(\"http://ec2-54-184-229-238.us-west-2.compute.amazonaws.com/\", \"admin@pronto.ai\", \"admin123!\")\n",
    "dataset_names = ['bdd_set', 'kache_set', 'holdout_set', 'china_set', 'pronto_set']\n",
    "get_dataset(anns_dir, data_pipeline_api, dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "set_batches = glob.glob(os.path.join(anns_dir, '*.json'))\n",
    "\n",
    "for set_batch in set_batches:\n",
    "    with open(set_batch, 'r') as f:\n",
    "        trn_set = json.load(f)\n",
    "        for idx, img_data in enumerate(trn_set):\n",
    "            img_data['labels'] = []\n",
    "    with open(set_batch, 'w') as f:\n",
    "        json.dump(trn_set, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import http\n",
    "from functools import wraps\n",
    "import ntpath\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import socket\n",
    "from pipelineapi import PipelineAPI\n",
    "import toml\n",
    "import os\n",
    "import json\n",
    "from subprocess import Popen,PIPE,STDOUT,call\n",
    "\n",
    "\n",
    "\n",
    "def path_leaf(path):\n",
    "    if urllib.parse.urlparse(path).scheme != \"\" or os.path.isabs(path):\n",
    "        path = os.path.split(path)[-1]\n",
    "\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import copy\n",
    "\n",
    "anns_dir = '/media/dean/datastore/datapipeline_api_dir/all_frames/'\n",
    "scalabel_anns_dir = '/media/dean/datastore/datapipeline_api_dir/all_frames/scalabel/'\n",
    "set_batches = glob.glob(os.path.join(anns_dir, '*.json'))\n",
    "scalabel_batches = glob.glob(os.path.join(scalabel_anns_dir, '*.json'))\n",
    "scalabel_dir = os.path.join(scalabel_anns_dir, 'scalabel_anns')\n",
    "os.makedirs(scalabel_dir, exist_ok = True)\n",
    "\n",
    "for scalabel_batch in scalabel_batches:\n",
    "    new_scalabel_batch = os.path.join(scalabel_dir, path_leaf(scalabel_batch))\n",
    "    with open(scalabel_batch, 'r') as f:\n",
    "        scalabel_set = json.load(f)\n",
    "    new_set = []    \n",
    "    for idx, scalabel_img_data in enumerate(scalabel_set):\n",
    "        # find labels from corresponding set_files\n",
    "        found_frame = False\n",
    "    \n",
    "    \n",
    "        for set_batch in set_batches:\n",
    "            if not found_frame:\n",
    "                with open(set_batch, 'r') as f:\n",
    "                    trn_set = json.load(f)\n",
    "                    for idx, img_data in enumerate(trn_set):\n",
    "                        # check for match\n",
    "                        if scalabel_img_data['url'] == img_data['url']:\n",
    "                            found_frame = True\n",
    "                            if scalabel_img_data.get('labels', None):\n",
    "                                for lbl in scalabel_img_data['labels']:\n",
    "                                    lbl['kache_label_id'] = None\n",
    "                                    lbl['scalabel_label_id'] = lbl['id']\n",
    "\n",
    "                                img_data['labels'] = copy.deepcopy(scalabel_img_data['labels'])\n",
    "                                new_set.append(copy.deepcopy(img_data))\n",
    "                                break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # img_data['labels'] = []\n",
    "    with open(new_scalabel_batch, 'w') as f:\n",
    "        json.dump(new_set, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "kache_dir = os.path.join(scalabel_dir, 'kache_sets')\n",
    "os.makedirs(kache_dir, exist_ok = True)\n",
    "\n",
    "kache_batches = glob.glob(os.path.join(scalabel_dir, '*.json'))\n",
    "for kache_batch in kache_batches:\n",
    "    dsets = defaultdict(list)\n",
    "    with open(kache_batch, 'r') as f:\n",
    "        kache_set = json.load(f)\n",
    "    for idx, img_data in enumerate(kache_set):\n",
    "        dsets[img_data['dataset_name']].append(copy.deepcopy(img_data))\n",
    "        \n",
    "    for dataset_name, dataset_data in dsets.items():\n",
    "        new_kache_set = os.path.join(kache_dir, os.path.splitext(path_leaf(kache_batch))[0]+'_'+dataset_name+os.path.splitext(path_leaf(kache_batch))[-1])\n",
    "        with open(new_kache_set, 'w') as f:\n",
    "            json.dump(dataset_data, f)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
