{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import scipy.misc\n",
    "from skimage import measure   \n",
    "from shapely.geometry import Polygon, MultiPolygon, MultiPoint\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = '/media/dean/datastore1/datasets/BerkeleyDeepDrive/'\n",
    "WORKING_DIR = os.path.join(BASE_DIR, 'scalabel/darknet/')\n",
    "IMAGE_LIST_DIR = os.path.join(BASE_DIR, 'bdd100k/images/100k/val/image_list.yml')\n",
    "LABEL_LIST_DIR = os.path.join(BASE_DIR, 'bdd100k/labels/bdd100k_labels_images_val.json')\n",
    "COCO_DIRECTORY = os.path.join(WORKING_DIR, 'data/coco')\n",
    "DATACACHE = os.path.join('/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014')\n",
    "img_prefix = 'COCO_train2014_0000'\n",
    "DEFAULT_IMG_EXTENSION = '.jpg'\n",
    "\n",
    "FIXED_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/fixed_instances_train2014.json')\n",
    "BDD10K_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/bdd10k_instances_val2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(source_url, filename):\n",
    "    os.makedirs(DATACACHE, exist_ok = True)\n",
    "    filepath = os.path.join(DATACACHE, filename)\n",
    "    if os.path.exists(source_url) and not os.path.exists(filepath):\n",
    "        # Copy image into training directory\n",
    "        print('Copying File', source_url, 'to file:', filepath)\n",
    "        shutil.copyfile(source_url, filepath)\n",
    "    elif not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(source_url, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        #print('Succesfully downloaded:', filepath, '| % d MB.\\n' % int(statinfo.st_size*1e-6))\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Format(Enum):\n",
    "    scalabel = 0\n",
    "    coco = 1\n",
    "    darknet = 2\n",
    "    bdd = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, image_list, label_list, data_format=Format.scalabel, output_path=WORKING_DIR, pickle_file = None):\n",
    "        self._images = {}\n",
    "        self._annotations = {}\n",
    "        \n",
    "        # Check if pickle_file is None or does not exist\n",
    "        if pickle_file and os.path.exists(pickle_file):\n",
    "            self._pickle_file = pickle_file\n",
    "            pickle_in = open(self._pickle_file,\"rb\")\n",
    "            pickle_dict = pickle.load(pickle_in)\n",
    "            self._images = pickle_dict['images']\n",
    "            self._annotations = pickle_dict['annotations']\n",
    "        else:\n",
    "            path = os.path.normpath(image_list)\n",
    "            self._pickle_file = \"{}.pickle\".format('_'.join(path.split(os.sep)[5:]))\n",
    "        \n",
    "        \n",
    "            if data_format == Format.scalabel:\n",
    "                with open(image_list, 'r') as stream:\n",
    "                    image_data = yaml.load(stream)\n",
    "                    if image_data:\n",
    "                        for img in image_data:\n",
    "                            img_url = img['url']\n",
    "                            fname = os.path.split(img_url)[-1]\n",
    "                            full_path = maybe_download(img_url, img_prefix+fname)\n",
    "                            im = Image.open(full_path)\n",
    "                            width, height = im.size\n",
    "                            self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                                 'width': width, 'height': height}\n",
    "\n",
    "\n",
    "                # Import Labels            \n",
    "                with open(label_list, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                    for ann in data:\n",
    "                        fname = os.path.split(ann['url'])[-1]\n",
    "                        self._annotations[img_prefix+fname] = ann['labels']\n",
    "                        img_data = self._images[img_prefix+fname]\n",
    "                        img_data['attributes'] = ann['attributes']\n",
    "                        img_data['videoName'] = ann['videoName']\n",
    "                        img_data['timestamp'] = ann['timestamp']\n",
    "                        img_data['index'] = ann['index']\n",
    "                        self._images[img_prefix+fname] = img_data\n",
    "\n",
    "\n",
    "            elif data_format == Format.bdd:\n",
    "                with open(image_list, 'r') as stream:\n",
    "                    image_data = yaml.load(stream)\n",
    "                    if image_data:\n",
    "                        for img in image_data:\n",
    "                            img_url = img['url']\n",
    "                            fname = os.path.split(img_url)[-1]\n",
    "                            full_path = maybe_download(img_url, img_prefix+fname)\n",
    "\n",
    "                            im = Image.open(full_path)\n",
    "                            width, height = im.size\n",
    "                            self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                                 'width': width, 'height': height}\n",
    "                    print('Image Length:', len(self._images))\n",
    "\n",
    "\n",
    "                # Get labels\n",
    "                \n",
    "                # Import Labels            \n",
    "                with open(label_list, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                    for ann in data:\n",
    "                        fname = ann['name']\n",
    "                        self._annotations[img_prefix+fname] = ann['labels']\n",
    "                        img_data = self._images[img_prefix+fname]\n",
    "                        img_data['attributes'] = ann['attributes']\n",
    "                        img_data['timestamp'] = ann['timestamp']\n",
    "                        self._images[img_prefix+fname] = img_data\n",
    "\n",
    "                        \n",
    "                        \n",
    "#                 img_labels = glob.glob(os.path.join(label_list, '*.json'))\n",
    "#                 for i, img_label in enumerate(img_labels):\n",
    "#                     with open(img_label, 'r') as f:\n",
    "#                         data = json.load(f)\n",
    "#                         fname = data['name']\n",
    "#                         if not fname.endswith(DEFAULT_IMG_EXTENSION):\n",
    "#                             fname = data['name']+DEFAULT_IMG_EXTENSION\n",
    "\n",
    "#                         self._annotations[img_prefix+fname] = []\n",
    "#                         for img_frame in data['frames']:\n",
    "#                             self._annotations[img_prefix+fname].extend(img_frame['objects'])\n",
    "                        \n",
    "#                         img_data = self._images[img_prefix+fname]\n",
    "#                         img_data['attributes'] = data['attributes']\n",
    "#                         self._images[img_prefix+fname] = img_data\n",
    "                        \n",
    "                        \n",
    "            # Save object to picklefile\n",
    "            pickle_dict = {'images':self._images,'annotations':self._annotations}\n",
    "            with open(self._pickle_file,\"wb\") as pickle_out:\n",
    "                pickle.dump(pickle_dict, pickle_out)            \n",
    "            \n",
    "        print(len(self._annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Length: 10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "example_set = Dataset(image_list = IMAGE_LIST_DIR, label_list = LABEL_LIST_DIR, data_format = Format.bdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3929 night images in this dataset.\n",
      "[{'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1c81faa-3df17267.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1c81faa-3df17267.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'highway', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1c81faa-c80764c5.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1c81faa-c80764c5.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'highway', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1ca2e5d-84cf9134.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1ca2e5d-84cf9134.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1ca8418-84a133a0.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1ca8418-84a133a0.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1cd1e94-26dd524f.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1cd1e94-26dd524f.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1ceb32e-3f481b43.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1ceb32e-3f481b43.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1ceb32e-813f84b2.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1ceb32e-813f84b2.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'undefined', 'scene': 'tunnel', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1d10d08-743fd86c.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1d10d08-743fd86c.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1d22449-117aa773.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1d22449-117aa773.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'highway', 'timeofday': 'night'}, 'timestamp': 10000}, {'url': '/media/dean/datastore1/datasets/BerkeleyDeepDrive/bdd100k/images/100k/val/b1d22449-15fb948f.jpg', 'coco_path': '/media/dean/datastore1/datasets/darknet_evaluate/data/coco/images/train2014/COCO_train2014_0000b1d22449-15fb948f.jpg', 'width': 1280, 'height': 720, 'attributes': {'weather': 'clear', 'scene': 'city street', 'timeofday': 'night'}, 'timestamp': 10000}]\n"
     ]
    }
   ],
   "source": [
    "night_images = [example_set._images[img] for img in example_set._images if 'night' in example_set._images[img]['attributes']['timeofday']]\n",
    "print('There are {} night images in this dataset.'.format(len(night_images)))\n",
    "print(night_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDD100K_LABELS_PATH = os.path.join('/media/dean/datastore1/datasets/Scripts/','BDD100k_Classes.csv')\n",
    "BDD100K_HEADER_ROW = ['class', 'super-category', 'special', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>super-category</th>\n",
       "      <th>special</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rider</td>\n",
       "      <td>rider</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bus</td>\n",
       "      <td>bus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class super-category  special  description\n",
       "0  person         person      NaN          NaN\n",
       "1   rider          rider      NaN          NaN\n",
       "2     car            car      NaN          NaN\n",
       "3   truck          truck      NaN          NaN\n",
       "4     bus            bus      NaN          NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get RoadCOCO Labels to Use as Ground Truth\n",
    "gt_labels = pd.read_csv(BDD100K_LABELS_PATH, names=BDD100K_HEADER_ROW, skiprows=1)\n",
    "gt_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'name': 'person', 'supercategory': 'person'}, {'id': 1, 'name': 'rider', 'supercategory': 'rider'}, {'id': 2, 'name': 'car', 'supercategory': 'car'}, {'id': 3, 'name': 'truck', 'supercategory': 'truck'}, {'id': 4, 'name': 'bus', 'supercategory': 'bus'}, {'id': 5, 'name': 'train', 'supercategory': 'train'}, {'id': 6, 'name': 'motor', 'supercategory': 'motor'}, {'id': 7, 'name': 'bike', 'supercategory': 'bike'}, {'id': 8, 'name': 'traffic sign', 'supercategory': 'traffic sign'}, {'id': 9, 'name': 'traffic light', 'supercategory': 'traffic light'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/miniconda3/envs/ros-kache/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Represent Category IDs using RoadCOCO Labels\n",
    "cats2ids = {}\n",
    "for i, label in enumerate(gt_labels['class'].tolist()):\n",
    "    cats2ids[str(label).lower()] = i\n",
    "ids2cats = {i: v for v, i in cats2ids.items()}\n",
    "    \n",
    "\n",
    "\n",
    "# Build Categories List in MS RoadCOCO Format\n",
    "categories = [] \n",
    "for label in gt_labels.as_matrix():\n",
    "    category = str(label[0]).lower()\n",
    "    cat_id = cats2ids[category]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sup_cat = ids2cats[cats2ids[str(label[1]).lower()]]\n",
    "    \n",
    "    categories.append({\"id\": cat_id, \"name\": category, \"supercategory\":sup_cat})   \n",
    "print (categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom BDD100k categories:\n",
      "person\n",
      "rider\n",
      "car\n",
      "truck\n",
      "bus\n",
      "train\n",
      "motor\n",
      "bike\n",
      "traffic sign\n",
      "traffic light\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fixed_coco = COCO(FIXED_COCO_ANNOTATIONS_FILE)\n",
    "#categories = fixed_coco.loadCats(fixed_coco.getCatIds())\n",
    "\n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom BDD100k categories:\\n{}\\n'.format('\\n'.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, anns = [], []\n",
    "img_offset, ann_index = 10000001, 100000000\n",
    "num_imgs = len(example_set._annotations.keys())\n",
    "    \n",
    "for img_id, fname in enumerate(example_set._annotations.keys()):\n",
    "    width, height = example_set._images[fname]['width'], example_set._images[fname]['height'] \n",
    "    \n",
    "    if not fname.startswith(img_prefix):\n",
    "        fname = img_prefix+fname\n",
    "    dic = {'file_name': fname, 'id': img_offset+img_id, 'height': height, 'width': width}\n",
    "    images.append(dic)\n",
    "    \n",
    "    # xy coords: [xstart, ystart, xstop, ystop] -> bbox = [x,y,width,height]\n",
    "    for annotation in [x for x in example_set._annotations[fname] if x['category'] in category_names]:\n",
    "        bbox = annotation['box2d']\n",
    "\n",
    "        if bbox:\n",
    "            # xy coords: [xstart, ystart, xstop, ystop] -> bbox = [x,y,width,height]\n",
    "            xstart, ystart, xstop, ystop = float(bbox['x1']),float(bbox['y1']),float(bbox['x2']),float(bbox['y2'])\n",
    "\n",
    "            if xstart < 0:\n",
    "                xstart = 0.0\n",
    "            if ystart < 0:\n",
    "                ystart = 0.0\n",
    "            if ystop <= 0:\n",
    "                ystop = 3.0\n",
    "            if xstop <= 0:\n",
    "                xstop = 3.0\n",
    "\n",
    "            # Get Points from Bounding Box\n",
    "            pts = []\n",
    "            pts.append((xstart , xstop))\n",
    "            pts.append((xstop , ystart))\n",
    "            pts.append((xstop , ystop))\n",
    "            pts.append((xstart , ystop))\n",
    "\n",
    "            segmentations = []\n",
    "            segmentations.append([])  \n",
    "            width = xstop - xstart\n",
    "            height = ystop - ystart\n",
    "            bbox = (xstart, ystart, width, height)\n",
    "            area = float(width*height)\n",
    "\n",
    "            annotation = {\n",
    "                'segmentation': segmentations,\n",
    "                'iscrowd': 0,\n",
    "                'image_id': img_offset+img_id, # Don't want to conflict with existing dataset\n",
    "                'category_id': cats2ids[annotation['category']],\n",
    "                'id': ann_index,\n",
    "                'bbox': bbox,\n",
    "                'area': area\n",
    "            }\n",
    "            ann_index+=1\n",
    "            anns.append(annotation)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185526\n"
     ]
    }
   ],
   "source": [
    "print(len(anns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"Road Object-Detections Dataset based on MS COCO\",\n",
    "    \"url\": \"https://kache.ai\",\n",
    "    \"version\": \"0.0.1\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"deanwebb\",\n",
    "    \"date_created\": datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"The MIT License (MIT)\",\n",
    "        \"url\": \"https://opensource.org/licenses/MIT\",\n",
    "        \"description\":  \"\"\"\n",
    "                        The MIT License (MIT)\n",
    "                        Copyright (c) 2017 Matterport, Inc.\n",
    "\n",
    "                        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "                        of this software and associated documentation files (the \"Software\"), to deal\n",
    "                        in the Software without restriction, including without limitation the rights\n",
    "                        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "                        copies of the Software, and to permit persons to whom the Software is\n",
    "                        furnished to do so, subject to the following conditions:\n",
    "\n",
    "                        The above copyright notice and this permission notice shall be included in\n",
    "                        all copies or substantial portions of the Software.\n",
    "\n",
    "                        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "                        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "                        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "                        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "                        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "                        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "                        THE SOFTWARE.\n",
    "                        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "coco_output = {'info': INFO, 'licenses': LICENSES, 'images':images, 'annotations':anns, 'categories': categories}\n",
    "with open(BDD10K_ANNOTATIONS_FILE, 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.35s)\n",
      "creating index...\n",
      "index created!\n",
      "{'file_name': 'COCO_train2014_0000bf42f468-f2b3301f.jpg', 'id': 10005333, 'height': 720, 'width': 1280}\n"
     ]
    }
   ],
   "source": [
    "testing_coco = COCO(BDD10K_ANNOTATIONS_FILE)\n",
    "category_ids = testing_coco.getCatIds(catNms=list(category_names))\n",
    "image_ids = testing_coco.getImgIds()\n",
    "image_data = testing_coco.loadImgs(image_ids[np.random.randint(0, len(image_ids))])[0]\n",
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185526\n"
     ]
    }
   ],
   "source": [
    "# load and display instance annotations\n",
    "image = io.imread(os.path.join(DATACACHE ,image_data['file_name']))\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (128.0, 180.0)\n",
    "annotation_ids = testing_coco.getAnnIds( catIds=category_ids, iscrowd=None)\n",
    "\n",
    "\n",
    "annotations = testing_coco.loadAnns(annotation_ids)\n",
    "print(len(annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON | Annotations: 13262  | Images:  3220\n",
      "RIDER | Annotations: 649  | Images:  515\n",
      "CAR | Annotations: 102506  | Images:  9879\n",
      "TRUCK | Annotations: 4245  | Images:  2689\n",
      "BUS | Annotations: 1597  | Images:  1242\n",
      "TRAIN | Annotations: 15  | Images:  14\n",
      "MOTOR | Annotations: 452  | Images:  334\n",
      "BIKE | Annotations: 1007  | Images:  578\n",
      "TRAFFIC SIGN | Annotations: 34908  | Images:  8221\n",
      "TRAFFIC LIGHT | Annotations: 26885  | Images:  5653\n"
     ]
    }
   ],
   "source": [
    "# Get Dataset Distribution\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for cat in category_ids:\n",
    "    annotation_ids = testing_coco.getAnnIds(catIds=[cat])\n",
    "    image_ids = testing_coco.getImgIds(catIds=[cat])\n",
    "    cat_nm = testing_coco.loadCats(ids=[cat])[0]['name']\n",
    "    dataset[cat] = (len(annotation_ids), len(image_ids))\n",
    "    \n",
    "    print(cat_nm.upper(), '| Annotations:', dataset[cat][0], ' | Images: ',  dataset[cat][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Annotations for Darknet training\n",
    "WORKING_DIRECTORY ='/media/dean/datastore1/datasets/darknet_evaluate'\n",
    "COCO_DIRECTORY = os.path.join(WORKING_DIRECTORY, 'data/coco')\n",
    "BDD10K_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY, 'annotations', 'bdd10k_instances_train2014.json')\n",
    "IMAGES_DIRECTORY = os.path.join(COCO_DIRECTORY, 'images', 'train2014')\n",
    "LABELS_DIRECTORY = os.path.join(COCO_DIRECTORY, 'labels','train2014')\n",
    "CATEGORY_NAMES = os.path.join(WORKING_DIRECTORY, 'data', 'coco.bdd100k.names')\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(COCO_DIRECTORY, 'labels/train2014/manifast.txt')):\n",
    "    yolo_convert_output = os.path.join(COCO_DIRECTORY, 'labels','convert2yolo_results.txt')\n",
    "    !python3 $WORKING_DIRECTORY/convert2Yolo/example.py --datasets COCO --img_path \"{IMAGES_DIRECTORY}\" --label \"{BDD10K_COCO_ANNOTATIONS_FILE}\" --convert_output_path \"{LABELS_DIRECTORY}\" --img_type [\".jpg\"] --manipast_path $LABELS_DIRECTORY --cls_list_file $CATEGORY_NAMES &>> $yolo_convert_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ros-kache]",
   "language": "python",
   "name": "conda-env-ros-kache-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
