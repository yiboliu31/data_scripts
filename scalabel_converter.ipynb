{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import scipy.misc\n",
    "from skimage import measure   \n",
    "from shapely.geometry import Polygon, MultiPolygon, MultiPoint\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import shutil\n",
    "\n",
    "WORKING_DIR = '/media/dean/datastore/datasets/BerkeleyDeepDrive/scalabel/'\n",
    "#IMAGE_LIST_DIR = os.path.join(WORKING_DIR, 'examples/image_list.yml')\n",
    "IMAGE_LIST_DIR = '/media/dean/datastore/datasets/BerkeleyDeepDrive/bdd100k/images/100k/train/image_list.yml'\n",
    "#LABEL_LIST_DIR = os.path.join(WORKING_DIR, 'examples/scalabel_results.json')\n",
    "LABEL_LIST_DIR = '/media/dean/datastore/datasets/BerkeleyDeepDrive/bdd100k/labels/100k/train/'\n",
    "COCO_DIRECTORY = os.path.join(WORKING_DIR, 'data/coco')\n",
    "DATACACHE = os.path.join(COCO_DIRECTORY, 'images/train2014')\n",
    "img_prefix = 'COCO_train2014_0000'\n",
    "DEFAULT_IMG_EXTENSION = '.jpg'\n",
    "\n",
    "FIXED_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/fixed_instances_train2014.json')\n",
    "SCALABEL_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/scalabel_instances_train2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(source_url, filename):\n",
    "    os.makedirs(DATACACHE, exist_ok = True)\n",
    "    filepath = os.path.join(DATACACHE, filename)\n",
    "    if os.path.exists(source_url) and not os.path.exists(filepath):\n",
    "        # Copy image into training directory\n",
    "        shutil.copyfile(source_url, filepath)\n",
    "    elif not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(source_url, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        #print('Succesfully downloaded:', filepath, '| % d MB.\\n' % int(statinfo.st_size*1e-6))\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Format(Enum):\n",
    "    scalabel = 0\n",
    "    coco = 1\n",
    "    darknet = 2\n",
    "    bdd = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, image_list, label_list, data_format=Format.scalabel, output_path=WORKING_DIR):\n",
    "        self._images = {}\n",
    "        self._annotations = {}\n",
    "        \n",
    "        if data_format == Format.scalabel:\n",
    "            with open(image_list, 'r') as stream:\n",
    "                image_data = yaml.load(stream)\n",
    "                if image_data:\n",
    "                    for img in image_data:\n",
    "                        img_url = img['url']\n",
    "                        fname = os.path.split(img_url)[-1]\n",
    "                        full_path = maybe_download(img_url, img_prefix+fname)\n",
    "                        im = Image.open(full_path)\n",
    "                        width, height = im.size\n",
    "                        self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                             'width': width, 'height': height}\n",
    "        \n",
    "            \n",
    "            # Import Labels            \n",
    "            with open(label_list, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                for ann in data:\n",
    "                    fname = os.path.split(ann['url'])[-1]\n",
    "                    self._annotations[img_prefix+fname] = ann['labels']\n",
    "                    \n",
    "                    \n",
    "        elif data_format == Format.bdd:\n",
    "            with open(image_list, 'r') as stream:\n",
    "                image_data = yaml.load(stream)\n",
    "                if image_data:\n",
    "                    for img in image_data:\n",
    "                        img_url = img['url']\n",
    "                        fname = os.path.split(img_url)[-1]\n",
    "                        full_path = maybe_download(img_url, img_prefix+fname)\n",
    "                        \n",
    "                        im = Image.open(full_path)\n",
    "                        width, height = im.size\n",
    "                        self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                             'width': width, 'height': height}\n",
    "            \n",
    "            \n",
    "            # Get labels\n",
    "            img_labels = glob.glob(os.path.join(label_list, '*.json'))\n",
    "            print(len(img_labels))\n",
    "            for i, img_label in enumerate(img_labels):\n",
    "                with open(img_label, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    fname = data['name']\n",
    "                    if not fname.endswith(DEFAULT_IMG_EXTENSION):\n",
    "                        fname = data['name']+DEFAULT_IMG_EXTENSION\n",
    "                        \n",
    "                    self._annotations[img_prefix+fname] = []\n",
    "                    for img_frame in data['frames']:\n",
    "                        self._annotations[img_prefix+fname].extend(img_frame['objects'])\n",
    "        print(len(self._annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "example_set = Dataset( image_list = IMAGE_LIST_DIR, label_list = LABEL_LIST_DIR, data_format = Format.bdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=41.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Custom COCO categories:\n",
      "person\n",
      "bicycle\n",
      "car\n",
      "motorcycle\n",
      "airplane\n",
      "bus\n",
      "train\n",
      "truck\n",
      "boat\n",
      "traffic light\n",
      "fire hydrant\n",
      "stop sign\n",
      "parking meter\n",
      "bench\n",
      "bird\n",
      "cat\n",
      "dog\n",
      "horse\n",
      "sheep\n",
      "cow\n",
      "elephant\n",
      "bear\n",
      "zebra\n",
      "giraffe\n",
      "backpack\n",
      "umbrella\n",
      "handbag\n",
      "tie\n",
      "suitcase\n",
      "frisbee\n",
      "skis\n",
      "snowboard\n",
      "sports ball\n",
      "kite\n",
      "baseball bat\n",
      "baseball glove\n",
      "skateboard\n",
      "surfboard\n",
      "tennis racket\n",
      "bottle\n",
      "wine glass\n",
      "cup\n",
      "fork\n",
      "knife\n",
      "spoon\n",
      "bowl\n",
      "banana\n",
      "apple\n",
      "sandwich\n",
      "orange\n",
      "broccoli\n",
      "carrot\n",
      "hot dog\n",
      "pizza\n",
      "donut\n",
      "cake\n",
      "chair\n",
      "couch\n",
      "potted plant\n",
      "bed\n",
      "dining table\n",
      "toilet\n",
      "tv\n",
      "laptop\n",
      "mouse\n",
      "remote\n",
      "keyboard\n",
      "cell phone\n",
      "microwave\n",
      "oven\n",
      "toaster\n",
      "sink\n",
      "refrigerator\n",
      "book\n",
      "clock\n",
      "vase\n",
      "scissors\n",
      "teddy bear\n",
      "hair drier\n",
      "toothbrush\n",
      "motor\n",
      "rider\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixed_coco = COCO(FIXED_COCO_ANNOTATIONS_FILE)\n",
    "\n",
    "categories = fixed_coco.loadCats(fixed_coco.getCatIds())\n",
    "category_names = [category['name'] for category in categories]\n",
    "category_names.extend(['motor', 'rider'])\n",
    "print('Custom COCO categories:\\n{}\\n'.format('\\n'.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, anns = [], []\n",
    "img_offset, ann_index = 10000001, 100000000\n",
    "num_imgs = len(example_set._annotations.keys())\n",
    "    \n",
    "for img_id, fname in enumerate(example_set._annotations.keys()):\n",
    "    width, height = example_set._images[fname]['width'], example_set._images[fname]['height'] \n",
    "    \n",
    "    if not fname.startswith(img_prefix):\n",
    "        fname = img_prefix+fname\n",
    "    dic = {'file_name': fname, 'id': img_offset+img_id, 'height': height, 'width': width}\n",
    "    images.append(dic)\n",
    "    \n",
    "        \n",
    "    # xy coords: [xstart, ystart, xstop, ystop] -> bbox = [x,y,width,height]\n",
    "    for annotation in [x for x in example_set._annotations[fname] if x['category'] in category_names]:\n",
    "        bbox = annotation['box2d']\n",
    "\n",
    "        if bbox:\n",
    "            # xy coords: [xstart, ystart, xstop, ystop] -> bbox = [x,y,width,height]\n",
    "            xstart, ystart, xstop, ystop = float(bbox['x1']),float(bbox['y1']),float(bbox['x2']),float(bbox['y2'])\n",
    "\n",
    "\n",
    "            if xstart < 0:\n",
    "                xstart = 0.0\n",
    "            if ystart < 0:\n",
    "                ystart = 0.0\n",
    "            if ystop <= 0:\n",
    "                ystop = 3.0\n",
    "            if xstop <= 0:\n",
    "                xstop = 3.0\n",
    "\n",
    "            # Get Points from Bounding Box\n",
    "            pts = []\n",
    "            pts.append((xstart , xstop))\n",
    "            pts.append((xstop , ystart))\n",
    "            pts.append((xstop , ystop))\n",
    "            pts.append((xstart , ystop))\n",
    "\n",
    "\n",
    "            # Convert XML Polygon pts to Coco-friendly bounding boxes\n",
    "            points = MultiPoint(pts)\n",
    "            xstart,ystart,xstop,ystop = points.bounds\n",
    "\n",
    "            # Cast to Integers\n",
    "            xstart,ystart,xstop,ystop = int(xstart),int(ystart),int(xstop),int(ystop)\n",
    "            im = Image.open(example_set._images[fname]['coco_path'])\n",
    "            binary_mask = np.zeros_like(im)[:,:,0]\n",
    "            binary_mask[int(xstart):int(xstop), int(ystart):int(ystop)] +=1\n",
    "\n",
    "\n",
    "            contours = measure.find_contours(binary_mask, 0.5, positive_orientation='low')\n",
    "            polygons = []\n",
    "            segmentations = []\n",
    "\n",
    "\n",
    "\n",
    "            for contour in contours:\n",
    "                poly = Polygon(contour)\n",
    "                poly = poly.simplify(1.0, preserve_topology=False)\n",
    "\n",
    "                if poly and poly.exterior:\n",
    "                    polygons.append(poly)\n",
    "                    segmentation = np.array(poly.exterior.coords).ravel().tolist()\n",
    "                    segmentations.append(segmentation)\n",
    "\n",
    "            # Combine the polygons to calculate the bounding box and area\n",
    "            multi_poly = MultiPolygon(polygons)\n",
    "            if multi_poly.bounds:\n",
    "                x, y, max_x, max_y = multi_poly.bounds\n",
    "                width = max_x - x\n",
    "                height = max_y - y\n",
    "                bbox = (x, y, width, height)\n",
    "                area = multi_poly.area\n",
    "\n",
    "\n",
    "\n",
    "                # Get Label\n",
    "                if annotation['category'] == 'motorbike' or annotation['category'] == 'motor'  or annotation['category'] == 'rider':\n",
    "                    category_id = fixed_coco.getCatIds(catNms=['motorcycle'])\n",
    "                else:\n",
    "                    category_id = fixed_coco.getCatIds(catNms=[annotation['category']])\n",
    "\n",
    "                if not category_id: #Hardcode tv for now\n",
    "                    category_id = fixed_coco.getCatIds(catNms=['tv'])\n",
    "\n",
    "                if type(category_id) == list:\n",
    "                    category_id = category_id[0]\n",
    "\n",
    "                annotation = {\n",
    "                    'segmentation': segmentations,\n",
    "                    'iscrowd': 0,\n",
    "                    'image_id': img_offset+img_id, # Don't want to conflict with existing dataset\n",
    "                    'category_id': category_id,\n",
    "                    'id': ann_index,\n",
    "                    'bbox': bbox,\n",
    "                    'area': area\n",
    "                }\n",
    "                ann_index+=1\n",
    "                anns.append(annotation)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778155\n"
     ]
    }
   ],
   "source": [
    "print(len(anns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"Road Object-Detections Dataset based on MS COCO\",\n",
    "    \"url\": \"https://kache.ai\",\n",
    "    \"version\": \"0.0.1\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"deanwebb\",\n",
    "    \"date_created\": datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"The MIT License (MIT)\",\n",
    "        \"url\": \"https://opensource.org/licenses/MIT\",\n",
    "        \"description\":  \"\"\"\n",
    "                        The MIT License (MIT)\n",
    "                        Copyright (c) 2017 Matterport, Inc.\n",
    "\n",
    "                        Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "                        of this software and associated documentation files (the \"Software\"), to deal\n",
    "                        in the Software without restriction, including without limitation the rights\n",
    "                        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "                        copies of the Software, and to permit persons to whom the Software is\n",
    "                        furnished to do so, subject to the following conditions:\n",
    "\n",
    "                        The above copyright notice and this permission notice shall be included in\n",
    "                        all copies or substantial portions of the Software.\n",
    "\n",
    "                        THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "                        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "                        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "                        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "                        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "                        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "                        THE SOFTWARE.\n",
    "                        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "coco_output = {'info': INFO, 'licenses': LICENSES, 'images':images, 'annotations':anns, 'categories': categories}\n",
    "with open(SCALABEL_COCO_ANNOTATIONS_FILE, 'w') as output_json_file:\n",
    "    json.dump(coco_output, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.56s)\n",
      "creating index...\n",
      "index created!\n",
      "{'file_name': 'COCO_train2014_0000466dcc6e-4104e6c3.jpg', 'id': 10046272, 'height': 720, 'width': 1280}\n"
     ]
    }
   ],
   "source": [
    "testing_coco = COCO(SCALABEL_COCO_ANNOTATIONS_FILE)\n",
    "category_ids = testing_coco.getCatIds(catNms=list(category_names))\n",
    "image_ids = testing_coco.getImgIds()\n",
    "image_data = testing_coco.loadImgs(image_ids[np.random.randint(0, len(image_ids))])[0]\n",
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778155\n"
     ]
    }
   ],
   "source": [
    "# load and display instance annotations\n",
    "image = io.imread(os.path.join(DATACACHE ,image_data['file_name']))\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (128.0, 180.0)\n",
    "annotation_ids = testing_coco.getAnnIds( catIds=category_ids, iscrowd=None)\n",
    "\n",
    "\n",
    "annotations = testing_coco.loadAnns(annotation_ids)\n",
    "print(len(annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ros-kache]",
   "language": "python",
   "name": "conda-env-ros-kache-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
