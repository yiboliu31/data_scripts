{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_config(path):\n",
    "    \"\"\"Parses the yolo-v3 layer configuration file and returns module definitions\"\"\"\n",
    "    file = open(path, 'r')\n",
    "    lines = file.read().split('\\n')\n",
    "    lines = [x for x in lines if x and not x.startswith('#')]\n",
    "    lines = [x.rstrip().lstrip() for x in lines] # get rid of fringe whitespaces\n",
    "    module_defs = []\n",
    "    for line in lines:\n",
    "        if line.startswith('['): # This marks the start of a new block\n",
    "            module_defs.append({})\n",
    "            module_defs[-1]['type'] = line[1:-1].rstrip()\n",
    "            if module_defs[-1]['type'] == 'convolutional':\n",
    "                module_defs[-1]['batch_normalize'] = 0\n",
    "        else:\n",
    "            key, value = line.split(\"=\")\n",
    "            value = value.strip()\n",
    "            module_defs[-1][key.rstrip()] = value.strip()\n",
    "\n",
    "    return module_defs\n",
    "\n",
    "\n",
    "def save_model_config(model_defs, path):\n",
    "    \"\"\"Saves the yolo-v3 layer configuration file\"\"\"\n",
    "    with open(path, 'w') as writer:\n",
    "        \n",
    "        for block in model_defs:\n",
    "            writer.write('['+ block['type'] +']'+'\\n')\n",
    "            [writer.write(str(k)+'='+str(v)+'\\n') for k,v in block.items() if k != 'type']\n",
    "            writer.write('\\n')\n",
    "    return path\n",
    "\n",
    "            \n",
    "def save_data_config(data_config, path):\n",
    "    \"\"\"Saves the yolo-v3 data configuration file\"\"\"\n",
    "    with open(path, 'w') as writer:\n",
    "        [writer.write(str(k)+'='+str(v)+'\\n') for k,v in data_config.items()]\n",
    "    return path\n",
    "\n",
    "\n",
    "def inject_model_config(dataset, model_config, hyperparams):\n",
    "    for i, block in enumerate(model_config):        \n",
    "        if block['type'] == 'net':\n",
    "            block['learning_rate'] = hyperparams['lr']\n",
    "            block['batch'] = hyperparams['batch']\n",
    "            block['subdivisions'] = hyperparams['subdivisions']\n",
    "            block['burn_in'] = len(dataset._images.items())//(hyperparams['gpus'] * hyperparams['batch'])\n",
    "            block['max_batches'] = len(dataset._images.items())//(hyperparams['gpus'] * hyperparams['batch']) * hyperparams['epochs']\n",
    "        elif block['type'] == 'yolo':\n",
    "            block['classes'] = len(dataset.category_names)\n",
    "            model_config[i-1]['filters'] = (len(dataset.category_names)+5)*3\n",
    "    return model_config\n",
    "\n",
    "\n",
    "def inject_data_config(dataset, data_config):\n",
    "    data_config['train'] = dataset.darknet_manifast\n",
    "    data_config['classes'] = len(dataset.category_names)\n",
    "    ## TODO: Add Validation Set\n",
    "    data_config['valid'] = dataset.darknet_manifast\n",
    "    data_config['names'] = dataset.names_config\n",
    "    backup_path = os.path.abspath(os.path.join(dataset.output_path, os.pardir, 'backup'))\n",
    "    os.makedirs(backup_path, exist_ok = True)\n",
    "    data_config['backup'] = os.path.abspath(os.path.join(dataset.output_path, os.pardir, 'backup'))\n",
    "    num_gpus = int(dataset.parse_nvidia_smi()['Attached GPUs'])\n",
    "    data_config['gpus'] = ','.join(str(i) for i in range(num_gpus))\n",
    "    \n",
    "    \n",
    "    return data_config\n",
    "            \n",
    "\n",
    "def parse_data_config(path):\n",
    "    \"\"\"Parses the data configuration file\"\"\"\n",
    "    options = dict()\n",
    "    options['gpus'] = '0,1'\n",
    "    with open(path, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == '' or line.startswith('#'):\n",
    "            continue\n",
    "        key, value = line.split('=')\n",
    "        options[key.strip()] = value.strip()\n",
    "    return options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from pycocotools.coco import COCO\n",
    "import xml.etree.cElementTree as ET\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import scipy.misc\n",
    "from skimage import measure   \n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from subprocess import Popen,PIPE,STDOUT,call \n",
    "from utils import datasets\n",
    "\n",
    "BDD100K_DIRECTORY = os.path.join('/media/dean/datastore1/datasets/BerkeleyDeepDrive', 'bdd100k')\n",
    "WORKING_DIRECTORY = '/media/dean/datastore1/datasets/darknet'\n",
    "\n",
    "TRAINERS_DIRECTORY = os.path.join(WORKING_DIRECTORY, 'trainers')\n",
    "ANNOTATIONS_FILE = os.path.join(BDD100K_DIRECTORY, 'labels/bdd100k_labels_images_train.json')\n",
    "COCO_ANNOTATIONS_FILE = os.path.join('/media/dean/datastore1/datasets/road_coco/darknet/data/coco/annotations/instances_train2014.json')\n",
    "\n",
    "BASE_DATA_CONFIG = os.path.join(WORKING_DIRECTORY, 'cfg', 'bdd100k.data')\n",
    "BASE_MODEL_CONFIG = os.path.join(WORKING_DIRECTORY, 'cfg', 'yolov3-bdd100k.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of COCO Images 82081\n",
      "Length of COCO Annotations: 604907\n",
      "loading annotations into memory...\n",
      "Done (t=2.87s)\n",
      "creating index...\n",
      "index created!\n",
      "########## DATASET DISTRIBUTION: ############\n",
      "\n",
      "AIRPLANE | Annotations: 3833  | Images:  2243\n",
      "APPLE | Annotations: 4308  | Images:  1171\n",
      "BACKPACK | Annotations: 6200  | Images:  3924\n",
      "BANANA | Annotations: 6912  | Images:  1618\n",
      "BASEBALL BAT | Annotations: 2400  | Images:  1804\n",
      "BASEBALL GLOVE | Annotations: 2689  | Images:  1884\n",
      "BEAR | Annotations: 903  | Images:  668\n",
      "BED | Annotations: 2905  | Images:  2539\n",
      "BENCH | Annotations: 6751  | Images:  3844\n",
      "BICYCLE | Annotations: 4955  | Images:  2287\n",
      "BIRD | Annotations: 7290  | Images:  2241\n",
      "BOAT | Annotations: 7590  | Images:  2098\n",
      "BOOK | Annotations: 17315  | Images:  3734\n",
      "BOTTLE | Annotations: 16983  | Images:  5968\n",
      "BOWL | Annotations: 10064  | Images:  5028\n",
      "BROCCOLI | Annotations: 4927  | Images:  1340\n",
      "BUS | Annotations: 4327  | Images:  2791\n",
      "CAKE | Annotations: 4551  | Images:  2080\n",
      "CAR | Annotations: 30785  | Images:  8606\n",
      "CARROT | Annotations: 5539  | Images:  1186\n",
      "CAT | Annotations: 3301  | Images:  2818\n",
      "CELL PHONE | Annotations: 4460  | Images:  3322\n",
      "CHAIR | Annotations: 27147  | Images:  8950\n",
      "CLOCK | Annotations: 4328  | Images:  3159\n",
      "COUCH | Annotations: 4113  | Images:  3170\n",
      "COW | Annotations: 5686  | Images:  1389\n",
      "CUP | Annotations: 14513  | Images:  6518\n",
      "DINING TABLE | Annotations: 11167  | Images:  8378\n",
      "DOG | Annotations: 3774  | Images:  3041\n",
      "DONUT | Annotations: 4977  | Images:  1062\n",
      "ELEPHANT | Annotations: 3905  | Images:  1518\n",
      "FIRE HYDRANT | Annotations: 1316  | Images:  1205\n",
      "FORK | Annotations: 3918  | Images:  2537\n",
      "FRISBEE | Annotations: 1862  | Images:  1511\n",
      "GIRAFFE | Annotations: 3596  | Images:  1798\n",
      "HAIR DRIER | Annotations: 135  | Images:  128\n",
      "HANDBAG | Annotations: 8778  | Images:  4861\n",
      "HORSE | Annotations: 4666  | Images:  2068\n",
      "HOT DOG | Annotations: 2023  | Images:  821\n",
      "KEYBOARD | Annotations: 1980  | Images:  1471\n",
      "KITE | Annotations: 6560  | Images:  1625\n",
      "KNIFE | Annotations: 5536  | Images:  3097\n",
      "LAPTOP | Annotations: 3415  | Images:  2475\n",
      "MICROWAVE | Annotations: 1189  | Images:  1089\n",
      "MOTORCYCLE | Annotations: 6021  | Images:  2442\n",
      "MOUSE | Annotations: 1517  | Images:  1290\n",
      "ORANGE | Annotations: 4597  | Images:  1216\n",
      "OVEN | Annotations: 2302  | Images:  2003\n",
      "PARKING METER | Annotations: 833  | Images:  481\n",
      "PERSON | Annotations: 185316  | Images:  45174\n",
      "PIZZA | Annotations: 4001  | Images:  2202\n",
      "POTTED PLANT | Annotations: 5918  | Images:  3084\n",
      "REFRIGERATOR | Annotations: 1875  | Images:  1671\n",
      "REMOTE | Annotations: 4122  | Images:  2180\n",
      "SANDWICH | Annotations: 3089  | Images:  1645\n",
      "SCISSORS | Annotations: 1073  | Images:  673\n",
      "SHEEP | Annotations: 6654  | Images:  1105\n",
      "SINK | Annotations: 3933  | Images:  3291\n",
      "SKATEBOARD | Annotations: 4012  | Images:  2511\n",
      "SKIS | Annotations: 4698  | Images:  2209\n",
      "SNOWBOARD | Annotations: 1960  | Images:  1170\n",
      "SPOON | Annotations: 4287  | Images:  2493\n",
      "SPORTS BALL | Annotations: 4392  | Images:  2986\n",
      "STOP SIGN | Annotations: 1372  | Images:  1214\n",
      "SUITCASE | Annotations: 4251  | Images:  1631\n",
      "SURFBOARD | Annotations: 4161  | Images:  2343\n",
      "TEDDY BEAR | Annotations: 3442  | Images:  1510\n",
      "TENNIS RACKET | Annotations: 3411  | Images:  2368\n",
      "TIE | Annotations: 4497  | Images:  2667\n",
      "TOASTER | Annotations: 156  | Images:  151\n",
      "TOILET | Annotations: 2873  | Images:  2317\n",
      "TOOTHBRUSH | Annotations: 1377  | Images:  700\n",
      "TRAFFIC LIGHT | Annotations: 9159  | Images:  2893\n",
      "TRAIN | Annotations: 3159  | Images:  2464\n",
      "TRUCK | Annotations: 7050  | Images:  4321\n",
      "TV | Annotations: 4036  | Images:  3191\n",
      "UMBRELLA | Annotations: 7865  | Images:  2749\n",
      "VASE | Annotations: 4623  | Images:  2530\n",
      "WINE GLASS | Annotations: 5618  | Images:  1771\n",
      "ZEBRA | Annotations: 3685  | Images:  1324\n",
      "\n",
      "###############################################\n",
      "\n",
      "Length of COCO Images 69863\n",
      "Length of COCO Annotations: 1286871\n",
      "loading annotations into memory...\n",
      "Done (t=7.61s)\n",
      "creating index...\n",
      "index created!\n",
      "########## DATASET DISTRIBUTION: ############\n",
      "\n",
      "BIKE | Annotations: 7210  | Images:  4343\n",
      "BUS | Annotations: 11672  | Images:  8993\n",
      "CAR | Annotations: 713211  | Images:  69072\n",
      "DRIVABLE AREA | Annotations: 0  | Images:  0\n",
      "LANE | Annotations: 0  | Images:  0\n",
      "MOTOR | Annotations: 3002  | Images:  2284\n",
      "PERSON | Annotations: 91349  | Images:  22076\n",
      "RIDER | Annotations: 4517  | Images:  3586\n",
      "TRAFFIC LIGHT | Annotations: 186117  | Images:  39237\n",
      "TRAFFIC SIGN | Annotations: 239686  | Images:  57154\n",
      "TRAIN | Annotations: 136  | Images:  105\n",
      "TRUCK | Annotations: 29971  | Images:  18890\n",
      "\n",
      "###############################################\n",
      "\n",
      "Successfully merged 36031 images | and  136721 annotations\n",
      "Length of COCO Annotations: 1423592\n",
      "loading annotations into memory...\n",
      "Done (t=7.73s)\n",
      "creating index...\n",
      "index created!\n",
      "########## DATASET DISTRIBUTION: ############\n",
      "\n",
      "BIKE | Annotations: 7210  | Images:  4343\n",
      "BUS | Annotations: 11672  | Images:  8993\n",
      "CAR | Annotations: 713211  | Images:  69072\n",
      "DRIVABLE AREA | Annotations: 0  | Images:  0\n",
      "LANE | Annotations: 0  | Images:  0\n",
      "MOTOR | Annotations: 3002  | Images:  2284\n",
      "PERSON | Annotations: 228070  | Images:  58107\n",
      "RIDER | Annotations: 4517  | Images:  3586\n",
      "TRAFFIC LIGHT | Annotations: 186117  | Images:  39237\n",
      "TRAFFIC SIGN | Annotations: 239686  | Images:  57154\n",
      "TRAIN | Annotations: 136  | Images:  105\n",
      "TRUCK | Annotations: 29971  | Images:  18890\n",
      "\n",
      "###############################################\n",
      "\n",
      "Saving to Pickle File: BerkeleyDeepDrive_bdd100k_labels_bdd100k_labels_images_train.json.pickle\n"
     ]
    }
   ],
   "source": [
    "## Prepare Dataset ##\n",
    "coco_set = datasets.DataFormatter(annotations_list = COCO_ANNOTATIONS_FILE, input_format = datasets.Format.coco,\n",
    "                                 output_path = os.path.join(WORKING_DIRECTORY,'data'),\n",
    "                                 trainer_prefix = 'COCO_train2014_0000', \n",
    "                                 s3_bucket = 'kache-scalabel/coco_dataset/images/train2014/')\n",
    "\n",
    "\n",
    "bdd_set = datasets.DataFormatter(annotations_list = ANNOTATIONS_FILE, input_format = datasets.Format.bdd,\n",
    "                                 output_path = os.path.join(WORKING_DIRECTORY,'data'),\n",
    "                                 trainer_prefix = 'COCO_train2014_0000', \n",
    "                                 s3_bucket = 'kache-scalabel/bdd100k/images/100k/train/')\n",
    "\n",
    "bdd_set.merge(coco_set, include=['person'], reject_new_categories = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
