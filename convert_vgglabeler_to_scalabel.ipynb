{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import scipy.misc\n",
    "from skimage import measure   \n",
    "from shapely.geometry import Polygon, MultiPolygon, MultiPoint\n",
    "import random\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "BASE_DIR = '/media/dean/datastore1/datasets/BerkeleyDeepDrive/'\n",
    "WORKING_DIR = os.path.join(BASE_DIR, 'scalabel/darknet/')\n",
    "IMAGE_LIST_DIR = os.path.join(BASE_DIR, 'bdd100k/images/100k/val/image_list.yml')\n",
    "LABEL_LIST_DIR = os.path.join(BASE_DIR, 'bdd100k/labels/100k/val/')\n",
    "COCO_DIRECTORY = os.path.join(WORKING_DIR, 'data/coco')\n",
    "DATACACHE = os.path.join(COCO_DIRECTORY, 'images/train2014')\n",
    "img_prefix = 'COCO_train2014_0000'\n",
    "DEFAULT_IMG_EXTENSION = '.jpg'\n",
    "\n",
    "FIXED_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/fixed_instances_train2014.json')\n",
    "BDD10K_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY,'annotations/bdd10k_instances_val2014.json')\n",
    "SCALABEL_FORMAT_ANNOTATIONS = os.path.join(COCO_DIRECTORY,'annotations/vgglabels_scalabel_format.json')\n",
    "\n",
    "## VGG Labeler Dataset Extraction Parameters ##\n",
    "VGG_ANNS_CSV = os.path.join(BASE_DIR,'data', 'night_detections.csv')\n",
    "HEADER_ROW=['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(source_url, filename):\n",
    "    os.makedirs(DATACACHE, exist_ok = True)\n",
    "    filepath = os.path.join(DATACACHE, filename)\n",
    "    if os.path.exists(source_url) and not os.path.exists(filepath):\n",
    "        # Copy image into training directory\n",
    "        print('Copying File', source_url, 'to file:', filepath)\n",
    "        shutil.copyfile(source_url, filepath)\n",
    "    elif not os.path.exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(source_url, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        #print('Succesfully downloaded:', filepath, '| % d MB.\\n' % int(statinfo.st_size*1e-6))\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_size</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>region_count</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_shape_attributes</th>\n",
       "      <th>region_attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://ec2-18-236-156-72.us-west-2.compute.ama...</td>\n",
       "      <td>441189</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":765,\"y\":515,\"width\":51,\"hei...</td>\n",
       "      <td>{\"type\":\"car\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://ec2-18-236-156-72.us-west-2.compute.ama...</td>\n",
       "      <td>441189</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":590,\"y\":512,\"width\":72,\"hei...</td>\n",
       "      <td>{\"type\":\"car\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://ec2-18-236-156-72.us-west-2.compute.ama...</td>\n",
       "      <td>441189</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":507,\"y\":524,\"width\":25,\"hei...</td>\n",
       "      <td>{\"type\":\"car\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://ec2-18-236-156-72.us-west-2.compute.ama...</td>\n",
       "      <td>441189</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":683,\"y\":521,\"width\":19,\"hei...</td>\n",
       "      <td>{\"type\":\"car\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://ec2-18-236-156-72.us-west-2.compute.ama...</td>\n",
       "      <td>441189</td>\n",
       "      <td>{}</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"name\":\"rect\",\"x\":668,\"y\":520,\"width\":14,\"hei...</td>\n",
       "      <td>{\"type\":\"car\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  file_size  \\\n",
       "0  http://ec2-18-236-156-72.us-west-2.compute.ama...     441189   \n",
       "1  http://ec2-18-236-156-72.us-west-2.compute.ama...     441189   \n",
       "2  http://ec2-18-236-156-72.us-west-2.compute.ama...     441189   \n",
       "3  http://ec2-18-236-156-72.us-west-2.compute.ama...     441189   \n",
       "4  http://ec2-18-236-156-72.us-west-2.compute.ama...     441189   \n",
       "\n",
       "  file_attributes  region_count  region_id  \\\n",
       "0              {}             5          0   \n",
       "1              {}             5          1   \n",
       "2              {}             5          2   \n",
       "3              {}             5          3   \n",
       "4              {}             5          4   \n",
       "\n",
       "                             region_shape_attributes region_attributes  \n",
       "0  {\"name\":\"rect\",\"x\":765,\"y\":515,\"width\":51,\"hei...    {\"type\":\"car\"}  \n",
       "1  {\"name\":\"rect\",\"x\":590,\"y\":512,\"width\":72,\"hei...    {\"type\":\"car\"}  \n",
       "2  {\"name\":\"rect\",\"x\":507,\"y\":524,\"width\":25,\"hei...    {\"type\":\"car\"}  \n",
       "3  {\"name\":\"rect\",\"x\":683,\"y\":521,\"width\":19,\"hei...    {\"type\":\"car\"}  \n",
       "4  {\"name\":\"rect\",\"x\":668,\"y\":520,\"width\":14,\"hei...    {\"type\":\"car\"}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_annotations = pd.read_csv(VGG_ANNS_CSV, names=HEADER_ROW, skiprows=1)\n",
    "vgg_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BDD100K_LABELS_PATH = os.path.join('/media/dean/datastore1/datasets/Scripts/','BDD100k_Classes.csv')\n",
    "BDD100K_HEADER_ROW = ['class', 'super-category', 'special', 'description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>super-category</th>\n",
       "      <th>special</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rider</td>\n",
       "      <td>rider</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bus</td>\n",
       "      <td>bus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class super-category  special  description\n",
       "0  person         person      NaN          NaN\n",
       "1   rider          rider      NaN          NaN\n",
       "2     car            car      NaN          NaN\n",
       "3   truck          truck      NaN          NaN\n",
       "4     bus            bus      NaN          NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get RoadCOCO Labels to Use as Ground Truth\n",
    "gt_labels = pd.read_csv(BDD100K_LABELS_PATH, names=BDD100K_HEADER_ROW, skiprows=1)\n",
    "gt_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom BDD100k categories:\n",
      "person\n",
      "rider\n",
      "car\n",
      "truck\n",
      "bus\n",
      "train\n",
      "motor\n",
      "bike\n",
      "traffic sign\n",
      "traffic light\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/miniconda3/envs/ros-kache/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Represent Category IDs using RoadCOCO Labels\n",
    "cats2ids = {}\n",
    "for i, label in enumerate(gt_labels['class'].tolist()):\n",
    "    cats2ids[str(label).lower()] = i\n",
    "ids2cats = {i: v for v, i in cats2ids.items()}\n",
    "    \n",
    "\n",
    "\n",
    "# Build Categories List in MS RoadCOCO Format\n",
    "categories = [] \n",
    "for label in gt_labels.as_matrix():\n",
    "    category = str(label[0]).lower()\n",
    "    cat_id = cats2ids[category]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sup_cat = ids2cats[cats2ids[str(label[1]).lower()]]\n",
    "    \n",
    "    categories.append({\"id\": cat_id, \"name\": category, \"supercategory\":sup_cat})   \n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom BDD100k categories:\\n{}\\n'.format('\\n'.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Format(Enum):\n",
    "    scalabel = 0\n",
    "    coco = 1\n",
    "    darknet = 2\n",
    "    bdd = 3\n",
    "    vgg = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, annotations_list, image_list = None, data_format=Format.scalabel, output_path=WORKING_DIR, pickle_file = None):\n",
    "        self._images = {}\n",
    "        self._annotations = {}\n",
    "        \n",
    "        # Check if pickle_file is None or does not exist\n",
    "        if pickle_file and os.path.exists(pickle_file):\n",
    "            self._pickle_file = pickle_file\n",
    "            pickle_in = open(self._pickle_file,\"rb\")\n",
    "            pickle_dict = pickle.load(pickle_in)\n",
    "            self._images = pickle_dict['images']\n",
    "            self._annotations = pickle_dict['annotations']\n",
    "        else:\n",
    "            path = os.path.normpath(image_list)\n",
    "            self._pickle_file = \"{}.pickle\".format('_'.join(path.split(os.sep)[5:]))\n",
    "        \n",
    "            # Scalabel Data Handler \n",
    "            if data_format == Format.scalabel:\n",
    "                with open(image_list, 'r') as stream:\n",
    "                    image_data = yaml.load(stream)\n",
    "                    if image_data:\n",
    "                        for img in image_data:\n",
    "                            img_url = img['url']\n",
    "                            fname = os.path.split(img_url)[-1]\n",
    "                            full_path = maybe_download(img_url, img_prefix+fname)\n",
    "                            im = Image.open(full_path)\n",
    "                            width, height = im.size\n",
    "                            self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                                 'width': width, 'height': height}\n",
    "\n",
    "\n",
    "                # Import Labels            \n",
    "                with open(annotations_list, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                    for ann in data:\n",
    "                        fname = os.path.split(ann['url'])[-1]\n",
    "                        self._annotations[img_prefix+fname] = ann['labels']\n",
    "                        img_data = self._images[img_prefix+fname]\n",
    "                        img_data['attributes'] = ann['attributes']\n",
    "                        img_data['videoName'] = ann['videoName']\n",
    "                        img_data['timestamp'] = ann['timestamp']\n",
    "                        img_data['index'] = ann['index']\n",
    "                        self._images[img_prefix+fname] = img_data\n",
    "\n",
    "                        \n",
    "            # BDD100K Data Handler \n",
    "            elif data_format == Format.bdd:\n",
    "                with open(image_list, 'r') as stream:\n",
    "                    image_data = yaml.load(stream)\n",
    "                    if image_data:\n",
    "                        for img in image_data:\n",
    "                            img_url = img['url']\n",
    "                            fname = os.path.split(img_url)[-1]\n",
    "                            full_path = maybe_download(img_url, img_prefix+fname)\n",
    "\n",
    "                            im = Image.open(full_path)\n",
    "                            width, height = im.size\n",
    "                            self._images[img_prefix+fname] = {'url': img_url, 'coco_path': full_path,\n",
    "                                                 'width': width, 'height': height}\n",
    "                    print('Image Length:', len(self._images))\n",
    "                # Get labels\n",
    "                img_labels = glob.glob(os.path.join(annotations_list, '*.json'))\n",
    "                for i, img_label in enumerate(img_labels):\n",
    "                    with open(img_label, 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                        fname = data['name']\n",
    "                        if not fname.endswith(DEFAULT_IMG_EXTENSION):\n",
    "                            fname = data['name']+DEFAULT_IMG_EXTENSION\n",
    "\n",
    "                        self._annotations[img_prefix+fname] = []\n",
    "                        for img_frame in data['frames']:\n",
    "                            self._annotations[img_prefix+fname].extend(img_frame['objects'])\n",
    "                        \n",
    "                        img_data = self._images[img_prefix+fname]\n",
    "                        img_data['attributes'] = data['attributes']\n",
    "                        self._images[img_prefix+fname] = img_data\n",
    "               \n",
    "            \n",
    "            # VGG Data Handler (Legacy system)\n",
    "            elif data_format == Format.vgg:\n",
    "                HEADER_ROW=['filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes', 'region_attributes']\n",
    "                vgg_annotations = pd.read_csv(annotations_list, names=HEADER_ROW, skiprows=1)\n",
    "                img_paths = sorted(set(vgg_annotations['filename'].tolist()))\n",
    "\n",
    "                num_imgs = len(img_paths)\n",
    "                ann_idx = int(5e6)\n",
    "\n",
    "                # loop through each image\n",
    "                urlstofilepaths = {}\n",
    "                img = {}\n",
    "                start_idx = int(1e6)\n",
    "                for idx, img_url in enumerate(img_paths, start=start_idx):\n",
    "                    img = {}\n",
    "                    # Download Image if not exist\n",
    "                    fname = '_'.join(img_url.split('/')[-2:])\n",
    "                    urlstofilepaths[img_url] = maybe_download(img_url, os.path.join(DATACACHE, img_prefix+fname))\n",
    "\n",
    "                    # Get Image Size in Bytes\n",
    "                    img_file_size =  os.stat(urlstofilepaths[img_url]).st_size\n",
    "                    img['name'] = img_prefix+fname\n",
    "                    img['url'] = img_url\n",
    "                    img['videoName'] = ''\n",
    "                    img['file_size'] = img_file_size\n",
    "                    img['index'] = idx\n",
    "                    img['timestamp'] = 10000                    \n",
    "                    img['labels'] = []\n",
    "                    img['attributes'] = {'weather': 'clear',\n",
    "                                         'scene': 'highway',\n",
    "                                         'timeofday': 'night'}                    \n",
    "                    self._images[img_prefix+fname] = img\n",
    "                    self._annotations[img_prefix+fname] = []\n",
    "                    \n",
    "                    for annotation in [x for x in vgg_annotations.as_matrix() if x[0].lower() == img_url.lower()]:\n",
    "                        ann = {}\n",
    "                        ann['id'] = ann_idx\n",
    "                        ann['attributes'] = {'Occluded': False, 'Truncated': False}\n",
    "                        ann['manual'] = True\n",
    "                        ann['poly2d'] = None\n",
    "                        ann['box3d'] = None\n",
    "                        ann['box2d'] = None\n",
    "                        d = ast.literal_eval(annotation[5])\n",
    "        \n",
    "                        if d:\n",
    "                            if float(d['x']) < 0.0:\n",
    "                                d['x'] = 0.0\n",
    "                            if float(d['y']) < 0.0:\n",
    "                                d['y'] = 0.0\n",
    "                            if float(d['height']) <= 0.0:\n",
    "                                d['height'] = 1.0\n",
    "\n",
    "                            if float(d['width']) <= 0.0:\n",
    "                                d['width'] = 1.0   \n",
    "                \n",
    "                            ann['box2d'] = {'x1': d['x'],\n",
    "                                            'x2': d['x'] + d['width'],\n",
    "                                            'y1': d['y'],\n",
    "                                            'y2': d['y'] + d['height']}\n",
    "                        \n",
    "                        \n",
    "                        cls = ast.literal_eval(annotation[6])\n",
    "                        cat = cls['type'].lower().strip()\n",
    "                        if not cat or cat == '' or cat == 'fire hydrant':\n",
    "                            continue\n",
    "                        elif cat == 'tlr':\n",
    "                            ann['attributes']['Traffic Light Color'] = [2, 'R']\n",
    "                            ann['category'] = 'traffic light'\n",
    "                        elif cat == 'tlg':\n",
    "                            ann['attributes']['Traffic Light Color'] = [1, 'G']\n",
    "                            ann['category'] = 'traffic light'\n",
    "                        elif cat == 'tla':\n",
    "                            ann['attributes']['Traffic Light Color'] = [3, 'Y']\n",
    "                            ann['category'] = 'traffic light'\n",
    "                        elif cat == 'tlna' or cat == 'traffic light':\n",
    "                            ann['attributes']['Traffic Light Color'] = [0, 'NA']\n",
    "                            ann['category'] = 'traffic light'\n",
    "                        elif cat == 'motorbike':\n",
    "                            ann['category'] = 'motor bike'\n",
    "                        elif cat == 'speedlimitsign' or cat == 'stop sign' or cat == 'cone' or cat == 'clock':\n",
    "                            cat = 'traffic sign'\n",
    "                        elif cat not in category_names:\n",
    "                            continue\n",
    "                        else: # Verify category exists\n",
    "                            ann['category'] =  ids2cats[cats2ids[cat]]\n",
    "                            \n",
    "                        \n",
    "                        img['labels'].append(ann)\n",
    "                        ann_idx += 1\n",
    "                    self._annotations[img_prefix+fname].extend(img['labels'])\n",
    "                        \n",
    "                        \n",
    "            # Save object to picklefile\n",
    "            pickle_dict = {'images':self._images,'annotations':self._annotations}\n",
    "            with open(self._pickle_file,\"wb\") as pickle_out:\n",
    "                pickle.dump(pickle_dict, pickle_out)            \n",
    "            \n",
    "        print(len(self._images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dean/miniconda3/envs/ros-kache/lib/python3.6/site-packages/ipykernel/__main__.py:114: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4056\n"
     ]
    }
   ],
   "source": [
    "example_set = Dataset(image_list = IMAGE_LIST_DIR, annotations_list = VGG_ANNS_CSV, data_format = Format.vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SCALABEL_FORMAT_ANNOTATIONS, 'w') as output_json_file:\n",
    "    imgs_list = list(example_set._images.values())\n",
    "    json.dump(imgs_list, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_images = [example_set._images[img] for img in example_set._images if 'night' in example_set._images[img]['attributes']['timeofday']]\n",
    "print('There are {} night images in this dataset.'.format(len(night_images)))\n",
    "print(night_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_coco = COCO(FIXED_COCO_ANNOTATIONS_FILE)\n",
    "#categories = fixed_coco.loadCats(fixed_coco.getCatIds())\n",
    "\n",
    "category_names = [category['name'] for category in categories]\n",
    "print('Custom BDD100k categories:\\n{}\\n'.format('\\n'.join(category_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and display instance annotations\n",
    "image = io.imread(os.path.join(DATACACHE ,image_data['file_name']))\n",
    "plt.imshow(image); plt.axis('off')\n",
    "pylab.rcParams['figure.figsize'] = (128.0, 180.0)\n",
    "annotation_ids = testing_coco.getAnnIds( catIds=category_ids, iscrowd=None)\n",
    "\n",
    "\n",
    "annotations = testing_coco.loadAnns(annotation_ids)\n",
    "print(len(annotations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Dataset Distribution\n",
    "\n",
    "dataset = {}\n",
    "\n",
    "for cat in category_ids:\n",
    "    annotation_ids = testing_coco.getAnnIds(catIds=[cat])\n",
    "    image_ids = testing_coco.getImgIds(catIds=[cat])\n",
    "    cat_nm = testing_coco.loadCats(ids=[cat])[0]['name']\n",
    "    dataset[cat] = (len(annotation_ids), len(image_ids))\n",
    "    \n",
    "    print(cat_nm.upper(), '| Annotations:', dataset[cat][0], ' | Images: ',  dataset[cat][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Annotations for Darknet training\n",
    "WORKING_DIRECTORY ='/media/dean/datastore/datasets/darknet_evaluate'\n",
    "COCO_DIRECTORY = os.path.join(WORKING_DIRECTORY, 'data/coco')\n",
    "BDD10K_COCO_ANNOTATIONS_FILE = os.path.join(COCO_DIRECTORY, 'annotations', 'bdd10k_instances_train2014.json')\n",
    "IMAGES_DIRECTORY = os.path.join(COCO_DIRECTORY, 'images', 'train2014')\n",
    "LABELS_DIRECTORY = os.path.join(COCO_DIRECTORY, 'labels','train2014')\n",
    "CATEGORY_NAMES = os.path.join(WORKING_DIRECTORY, 'data', 'coco.bdd100k.names')\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(COCO_DIRECTORY, 'labels/train2014/manifast.txt')):\n",
    "    yolo_convert_output = os.path.join(COCO_DIRECTORY, 'labels','convert2yolo_results.txt')\n",
    "    !python3 $WORKING_DIRECTORY/convert2Yolo/example.py --datasets COCO --img_path \"{IMAGES_DIRECTORY}\" --label \"{BDD10K_COCO_ANNOTATIONS_FILE}\" --convert_output_path \"{LABELS_DIRECTORY}\" --img_type [\".jpg\"] --manipast_path $LABELS_DIRECTORY --cls_list_file $CATEGORY_NAMES &>> $yolo_convert_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ros-kache]",
   "language": "python",
   "name": "conda-env-ros-kache-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
